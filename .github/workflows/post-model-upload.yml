name: Post model upload actions

on:
  workflow_call:
    inputs:
      branch:
        required: false
        type: string
        default: "main"
      repo_name:
        required: true
        type: string
      runner:
        required: true
        type: string
    secrets:
      AIRTABLE_API_KEY:
        required: true
      AWS_ACCESS_KEY:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      DOCKERHUB_USERNAME:
        required: true
      DOCKERHUB_PASSWORD:
        required: true
jobs:
  post-model-upload:
    runs-on: ${{ inputs.runner }}
    steps:

      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Check if any tag exists
        id: check-tags
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Returns first tag name or empty string if none
          TAG="$(gh api repos/${{ github.repository }}/tags --paginate -q '.[0].name' || true)"
          if [[ -n "$TAG" ]]; then
            echo "has_tags=true"  >> "$GITHUB_OUTPUT"
            echo "TAG=${TAG}" >> $GITHUB_ENV
            echo "Found existing tag: $TAG"
          else
            echo "has_tags=false" >> "$GITHUB_OUTPUT"
            echo "No tags found in repository."
          fi

      - name: Create initial v1.0.0 release (only if no tags exist)
        if: steps.check-tags.outputs.has_tags == 'false'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # If this workflow was triggered by workflow_run, use the upstream run's head_sha; otherwise use this run's sha.
          TARGET_SHA="${{ github.sha }}"
          if [[ "${{ github.event_name }}" == "workflow_run" ]]; then
            TARGET_SHA="${{ github.event.workflow_run.head_sha }}"
          fi
          TAG="v1.0.0"
          echo "TAG=${TAG}" >> $GITHUB_ENV
          echo "Creating initial release ${TAG} at ${TARGET_SHA}"
          gh release create "${TAG}" \
            --target "${TARGET_SHA}" \
            --title "Release ${TAG}" \
            --generate-notes
      
      - name: Login to Docker Hub
        if: steps.check-tags.outputs.has_tags == 'false'
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}
      
      - name: Retag latest -> release tag
        if: steps.check-tags.outputs.has_tags == 'false'
        run: |
          echo "Retagging ersiliaos/${MODEL}:latest as ersiliaos/${MODEL}:${RELEASE_TAG}"
          docker buildx imagetools create \
            --tag ersiliaos/${MODEL}:${RELEASE_TAG} \
            ersiliaos/${MODEL}:latest
          echo "Done."

      - name: Download architecture file
        uses: actions/download-artifact@v4
        with:
          name: architecture
          path: .

      - name: Download amd64 test results
        uses: actions/download-artifact@v4
        with:
          name: test-report-amd64
          path: .

      - name: Extract report numbers
        env:
          MODEL_ID: ${{ inputs.repo_name }}
        run: |
          JSON_FILE="./${MODEL_ID}-test-amd64.json"  
          export IMAGE_SIZE=$(jq -r '.model_size_check.image_size_mb' $JSON_FILE)
          echo "IMAGE_SIZE=${IMAGE_SIZE}" >> $GITHUB_ENV
          for i in 1 2 3 4 5; do
            VALUE=$(jq -r ".computational_performance_summary.computational_performance_tracking_details.pred_${i}" $JSON_FILE)
            export COMPUTATIONAL_PERFORMANCE_${i}="$VALUE"
            echo "COMPUTATIONAL_PERFORMANCE_${i}=${VALUE}" >> $GITHUB_ENV
          done
          
          cat $JSON_FILE

      - name: Install pyaml and ruamel.yaml
        run: |
          pip install pyaml
          pip install ruamel.yaml

      - name: Extract Last Packaging Date
        run: |
          LAST_PACKAGING_DATE=$(date -u -d "${{ github.run_started_at }}" +%Y-%m-%d)
          echo "LAST_PACKAGING_DATE=$LAST_PACKAGING_DATE" >> $GITHUB_ENV

      - name: Update metadata fields
        env:
          MODEL_ID: ${{ github.event.repository.name }}
          IMAGE_SIZE: ${{ env.IMAGE_SIZE }}
          COMPUTATIONAL_PERFORMANCE_1: ${{ env.COMPUTATIONAL_PERFORMANCE_1 }}
          COMPUTATIONAL_PERFORMANCE_2: ${{ env.COMPUTATIONAL_PERFORMANCE_2 }}
          COMPUTATIONAL_PERFORMANCE_3: ${{ env.COMPUTATIONAL_PERFORMANCE_3 }}
          COMPUTATIONAL_PERFORMANCE_4: ${{ env.COMPUTATIONAL_PERFORMANCE_4 }}
          COMPUTATIONAL_PERFORMANCE_5: ${{ env.COMPUTATIONAL_PERFORMANCE_5 }}
          LAST_PACKAGING_DATE: ${{ env.LAST_PACKAGING_DATE }}
          TAG : ${{ env.TAG }}
        run: |
          if [[ -f metadata.yml ]]; then
            METADATA_FILE="metadata.yml"
          else
            METADATA_FILE="metadata.json"
          fi

          wget -O add_field_to_metadata.py https://raw.githubusercontent.com/ersilia-os/ersilia-model-workflows/main/.github/scripts/add_field_to_metadata.py
          python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "Status" --content "Ready"
          python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "DockerHub" --content "https://hub.docker.com/r/ersiliaos/${MODEL_ID}"
          python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "Docker Architecture" --content arch.txt
          python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "Image Size" --content "$IMAGE_SIZE"
          python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "Last Packaging Date" --content "$LAST_PACKAGING_DATE"
          python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "Release" --content "$TAG"
          for i in 1 2 3 4 5; do
            FIELD_NAME="Computational Performance ${i}"
            VALUE_VAR="COMPUTATIONAL_PERFORMANCE_${i}"
            python add_field_to_metadata.py --metadata_file "$METADATA_FILE" --field "$FIELD_NAME" --content "${!VALUE_VAR}"
          done

          cat "$METADATA_FILE"
          rm add_field_to_metadata.py

      - name: Remove downloaded artifacts
        env:
          MODEL_ID: ${{ inputs.repo_name }}
        run: |
            rm -rf architecture
            rm -rf test-report-amd64
            rm -f arch.txt "${MODEL_ID}-test-amd64.json"
          
      - name: Commit and push changes done to the Metadata file
        uses: actions-js/push@master # pin@v1.4
        with:
          author_name: "ersilia-bot"
          author_email: "ersilia-bot@users.noreply.github.com"
          message: "updating metadata [skip ci]"
          repository: "ersilia-os/${{ github.event.repository.name }}"
          github_token: ${{ secrets.GITHUB_TOKEN }}

      # Setup conda
      - name: Setup conda
        id: setupConda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: "3.12"
  
      # Install ersilia
      - name: Install dependencies in Conda environment
        id: installDependenciesInConda
        run: |
          conda run -n base conda install gh -c conda-forge
          conda run -n base python -m pip install git+https://github.com/ersilia-os/ersilia.git

      - name: Update metadata to AirTable
        id: update-metadata-to-airtable
        env:
          USER_NAME: ${{ github.repository_owner }}
          BRANCH: "main"
          REPO_NAME: ${{ github.event.repository.name }}
          AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
        run: |
          conda run -n base pip install requests pyairtable
          echo "Updating metadata to AirTable looking at owner: $USER_NAME"
          wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/airtableops.py
          wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/readme_formatter.py
          conda run -n base python3 airtableops.py airtable-update --user $USER_NAME --repo $REPO_NAME --branch $BRANCH --api-key $AIRTABLE_API_KEY
          rm airtableops.py
          rm readme_formatter.py
  
      - name: sync metadata to S3 JSON
        id: sync-metadata-to-s3
        env:
          AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/convert_airtable_to_json.py
          conda run -n base pip install boto3 requests pyairtable
          conda run -n base python convert_airtable_to_json.py $AIRTABLE_API_KEY $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY
          rm convert_airtable_to_json.py

      - name: Update README file
        id: update-readme-file
        env:
          MODEL_ID: ${{ github.event.repository.name }}
        run: |
          echo "Updating README file with AirTable metadata for model: $MODEL_ID"
          wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/airtableops.py
          wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/readme_formatter.py
          conda run -n base python3 airtableops.py readme-update --repo $MODEL_ID --path .
          rm airtableops.py
          rm readme_formatter.py
          less README.md

      - name: Commit and push changes done to the README file
        uses: actions-js/push@master # pin@v1.4
        with:
          author_name: "ersilia-bot"
          author_email: "ersilia-bot@users.noreply.github.com"
          message: "updating readme [skip ci]"
          repository: "ersilia-os/${{ github.event.repository.name }}"
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Docker Hub Description
        uses: peter-evans/dockerhub-description@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}
          repository: ersiliaos/${{ github.event.repository.name }}
          short-description: "Ersilia Model Hub Identifier: ${{ github.event.repository.name }}"
 