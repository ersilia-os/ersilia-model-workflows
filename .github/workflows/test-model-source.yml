name: Model test on push

on:
  workflow_call:
    inputs:
      branch:
        required: false
        type: string
        default: "main"
      repo_name:
        required: true
        type: string
    secrets:
      AIRTABLE_API_KEY:
        required: true
      AWS_ACCESS_KEY:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true

jobs:
  model-test:
    runs-on: ubuntu-latest
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@main
        with:
          # this might remove tools that are actually needed,
          # if set to "true" but frees about 6 GB
          tool-cache: true
          # all of these default to true, but feel free to set to
          # "false" if necessary for your workflow
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          swap-storage: true

      - uses: actions/checkout@v4.2.2
        with:
          lfs: true
          
      - uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: "3.12"
          auto-activate-base: false

      - name: Install dependencies
        run: |
          conda run -n base git-lfs install
          conda run -n base conda install gh -c conda-forge
          conda run -n base python -m pip install 'git+https://github.com/ersilia-os/ersilia.git#egg=ersilia[test]'

      - name: Update metadata to or from AirTable
        env:
          USER_NAME: ${{ github.repository_owner }}
          BRANCH: ${{ inputs.branch }}
          REPO_NAME: ${{ inputs.repo_name }}
          AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 10
          max_attempts: 3
          command: |
            set -e  # Ensure failure stops execution
            conda run -n base pip install requests pyairtable
            
            wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/airtableops.py

            # check if we have a YAML or JSON file
            if [ -f "metadata.yml" ]; then
              metadata="metadata.yml"
            elif [ -f "metadata.json" ]; then
              metadata="metadata.json"
            else
              echo "No metadata file found."
              exit 1
            fi

            echo "Found metadata file: $metadata"

            # Check the "Output Consistency" field based on file type.
            if [[ "$metadata" == "metadata.json" ]]; then
              # Extract the "Output Consistency" field from JSON.
              output_consistency=$(jq -r '.["Output Consistency"] // empty' "$metadata")
            elif [[ "$metadata" == "metadata.yml" ]]; then
              # Extract the "Output Consistency" field from YAML.
              output_consistency=$(yq e '.["Output Consistency"] // ""' "$metadata")
            fi

            # Verify that the field exists and is non-empty.
            if [ -n "$output_consistency" ]; then
              echo "'Output Consistency' exists and has value: $output_consistency"
              echo "Updating metadata to AirTable looking at owner: $USER_NAME"
              conda run -n base python3 airtableops.py airtable-update --user $USER_NAME --repo $REPO_NAME --branch $BRANCH --api-key $AIRTABLE_API_KEY
            else
              echo "'Output Consistency' is missing or empty in $metadata."
              echo "Updating metadata from AirTable looking at owner: $USER_NAME"
              conda run -n base python3 airtableops.py metadata-update --repo $REPO_NAME --commit True --api-key $AIRTABLE_API_KEY
            fi

            # remove file
            rm airtableops.py

      - name: Sync metadata to S3 JSON
        env:
          AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/convert_airtable_to_json.py
          conda run -n base pip install boto3 requests pyairtable
          conda run -n base python convert_airtable_to_json.py $AIRTABLE_API_KEY $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY
          rm convert_airtable_to_json.py

      - name: Update README file
        id: update-readme-file
        env:
          MODEL_ID: ${{ github.event.repository.name }}
        run: |
          conda run -n base bash -c "
            echo 'Updating README file with AirTable metadata for model: $MODEL_ID' &&
            wget https://raw.githubusercontent.com/ersilia-os/ersilia/master/.github/scripts/airtableops.py &&
            python3 airtableops.py readme-update --repo $MODEL_ID --path . &&
            rm airtableops.py &&
            less README.md
          "

      - name: Commit and push changes done to the README file
        uses: actions-js/push@156f2b10c3aa000c44dbe75ea7018f32ae999772 # pin@v1.4
        with:
          author_name: "ersilia-bot"
          author_email: "ersilia-bot@users.noreply.github.com"
          message: "updating readme [skip ci]"
          repository: "ersilia-os/${{ github.event.repository.name }}"
          github_token: ${{ secrets.GITHUB_TOKEN }}
          amend: true
          force: true

      - name: Fetch model and run #TODO change for test command 
        env:
          MODEL_ID: ${{ inputs.repo_name }}
        run: |
          conda run -n base bash -c "
            ersilia -v fetch $MODEL_ID --from_github &&
            ersilia serve $MODEL_ID &&
            ersilia example -f input.csv -n 3 &&
            ersilia run -i input.csv -o output.csv &&
            ersilia close &&
            ersilia delete $MODEL_ID &&
            head output.csv
          "

      - name: Upload log output
        if: always()
        uses: actions/upload-artifact@v4.5.0
        with:
          name: debug-logs
          retention-days: 14
          path: |
            /home/runner/eos/*.log
            ./*.log
